
Step 1: Kaggle download + imports


!pip -q install kaggle

import os, json, shutil, random
from pathlib import Path

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

print("TensorFlow:", tf.__version__)
print("GPU:", tf.config.list_physical_devices("GPU"))
     
TensorFlow: 2.19.0
GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Step 2: Download CelebA from Kaggle


!pip -q install kaggle

import os, json
from pathlib import Path
from getpass import getpass

KAGGLE_USERNAME = input("Kaggle username: ")
KAGGLE_KEY = getpass("Kaggle API key (hidden): ")

kaggle_dir = Path.home() / ".kaggle"
kaggle_dir.mkdir(parents=True, exist_ok=True)

kaggle_json_path = kaggle_dir / "kaggle.json"
with open(kaggle_json_path, "w") as f:
    json.dump({"username": KAGGLE_USERNAME, "key": KAGGLE_KEY}, f)

os.chmod(kaggle_json_path, 0o600)
print(" kaggle.json created at:", kaggle_json_path)

data_root = Path("/content/celeba_kaggle")
data_root.mkdir(parents=True, exist_ok=True)

!kaggle datasets download -d jessicali9530/celeba-dataset -p {data_root} --unzip
!ls -lah {data_root}
     
Kaggle username: prithilasaha
Kaggle API key (hidden): ··········
kaggle.json created at: /root/.kaggle/kaggle.json
Dataset URL: https://www.kaggle.com/datasets/jessicali9530/celeba-dataset
License(s): other
Downloading celeba-dataset.zip to /content/celeba_kaggle
100% 1.33G/1.33G [00:48<00:00, 4.14MB/s]
100% 1.33G/1.33G [00:48<00:00, 29.3MB/s]
total 45M
drwxr-xr-x 3 root root 4.0K Jan  7 21:15 .
drwxr-xr-x 1 root root 4.0K Jan  7 21:02 ..
-rw-r--r-- 1 root root 3.3M Jan  7 20:37 identity_CelebA.txt
drwxr-xr-x 3 root root 4.0K Jan  7 20:35 img_align_celeba
-rw-r--r-- 1 root root  24M Jan  7 21:15 list_attr_celeba.csv
-rw-r--r-- 1 root root 5.2M Jan  7 21:15 list_bbox_celeba.csv
-rw-r--r-- 1 root root 2.8M Jan  7 21:15 list_eval_partition.csv
-rw-r--r-- 1 root root 9.5M Jan  7 21:15 list_landmarks_align_celeba.csv
Step 3: Locate image folder + identity labels


from pathlib import Path
import os

data_root = Path("/content/celeba_kaggle")

# Find image folder
img_dir = None
for cand in ["img_align_celeba", "img_align_celeba/img_align_celeba"]:
    hits = list(data_root.rglob(cand))
    if hits:
        img_dir = hits[0]
        break

print("img_dir:", img_dir)
if img_dir is None:
    raise FileNotFoundError("Could not find img_align_celeba folder inside your dataset.")

# Find identity file
identity_path = None
hits = list(data_root.rglob("identity_CelebA.txt"))
if hits:
    identity_path = hits[0]

if identity_path is None:
    identity_path = data_root / "identity_CelebA.txt"
    !wget -q -O "{identity_path}" https://raw.githubusercontent.com/Golbstein/keras-face-recognition/master/identity_CelebA.txt
    print("Downloaded identity file to:", identity_path)

# Sanity check
if not identity_path.exists() or identity_path.stat().st_size < 1000:
    raise FileNotFoundError("identity_CelebA.txt is missing or too small; download failed.")

print("identity_path:", identity_path)
print("identity file size (bytes):", identity_path.stat().st_size)
     
img_dir: /content/celeba_kaggle/img_align_celeba
identity_path: /content/celeba_kaggle/identity_CelebA.txt
identity file size (bytes): 3424458
Step 4: Dataset Splitting


import shutil, random
from pathlib import Path

SEED = 42
random.seed(SEED)

src_root = Path("/content/reduced_celeba")
dst_root = Path("/content/reduced_celeba_split")

TRAIN_PER_CLASS = 20
VAL_PER_CLASS = 5

if dst_root.exists():
    shutil.rmtree(dst_root)
(dst_root / "train").mkdir(parents=True, exist_ok=True)
(dst_root / "val").mkdir(parents=True, exist_ok=True)

class_dirs = sorted([d for d in src_root.iterdir() if d.is_dir()])
print("Classes found:", len(class_dirs))

for cls_dir in class_dirs:
    imgs = sorted(list(cls_dir.glob("*.jpg")))
    random.shuffle(imgs)

    if len(imgs) < TRAIN_PER_CLASS + VAL_PER_CLASS:
        raise ValueError(f"{cls_dir.name} has only {len(imgs)} images. Need {TRAIN_PER_CLASS+VAL_PER_CLASS}.")

    train_imgs = imgs[:TRAIN_PER_CLASS]
    val_imgs = imgs[TRAIN_PER_CLASS:TRAIN_PER_CLASS + VAL_PER_CLASS]

    (dst_root / "train" / cls_dir.name).mkdir(parents=True, exist_ok=True)
    (dst_root / "val" / cls_dir.name).mkdir(parents=True, exist_ok=True)

    for p in train_imgs:
        shutil.copy2(p, dst_root / "train" / cls_dir.name / p.name)
    for p in val_imgs:
        shutil.copy2(p, dst_root / "val" / cls_dir.name / p.name)

print(" Done.")
print("Train images:", sum(1 for _ in (dst_root/'train').rglob('*.jpg')))
print("Val images:", sum(1 for _ in (dst_root/'val').rglob('*.jpg')))
     
Classes found: 10
 Done.
Train images: 200
Val images: 50
Step 5: Dataset Loading and Preprocessing


import tensorflow as tf

IMG_SIZE = (160, 160)
BATCH_SIZE = 16
SEED = 42

train_ds = tf.keras.utils.image_dataset_from_directory(
    "/content/reduced_celeba_split/train",
    label_mode="categorical",
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=True,
    seed=SEED,
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    "/content/reduced_celeba_split/val",
    label_mode="categorical",
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=False,
)

NUM_CLASSES = len(train_ds.class_names)
print("NUM_CLASSES:", NUM_CLASSES)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().prefetch(AUTOTUNE)
val_ds = val_ds.cache().prefetch(AUTOTUNE)

     
Found 200 files belonging to 10 classes.
Found 50 files belonging to 10 classes.
NUM_CLASSES: 10
Step 6: Model Architecture and Training


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

aug = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.02),
    layers.RandomZoom(0.05),
], name="aug")

def ln_relu(x, name):
    x = layers.LayerNormalization(epsilon=1e-6, name=f"{name}_ln")(x)
    return layers.ReLU(6., name=f"{name}_relu")(x)

def dw_ln_block(x, out_ch, stride, name):
    in_ch = x.shape[-1]
    shortcut = x

    x = layers.DepthwiseConv2D(3, strides=stride, padding="same", use_bias=False, name=f"{name}_dw")(x)
    x = ln_relu(x, f"{name}_a")

    x = layers.Conv2D(out_ch, 1, padding="same", use_bias=False, name=f"{name}_pw")(x)
    x = ln_relu(x, f"{name}_b")

    if stride == 1 and in_ch == out_ch:
        x = layers.Add(name=f"{name}_add")([x, shortcut])
    return x

def build_task1(input_shape, num_classes):
    inp = keras.Input(shape=input_shape)
    x = aug(inp)
    x = layers.Rescaling(1./255)(x)

    x = layers.Conv2D(32, 3, strides=2, padding="same", use_bias=False)(x)
    x = ln_relu(x, "stem")

    x = dw_ln_block(x, 64,  1, "b1")
    x = dw_ln_block(x, 128, 2, "b2")
    x = dw_ln_block(x, 128, 1, "b3")
    x = dw_ln_block(x, 256, 2, "b4")
    x = dw_ln_block(x, 256, 1, "b5")
    x = dw_ln_block(x, 256, 1, "b6")

    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.1)(x)
    out = layers.Dense(num_classes, activation="softmax")(x)
    return keras.Model(inp, out, name="task1_scratch")

model1 = build_task1(IMG_SIZE + (3,), NUM_CLASSES)
model1.summary()

steps = tf.data.experimental.cardinality(train_ds).numpy()
EPOCHS = 80
lr = keras.optimizers.schedules.CosineDecay(1e-3, steps * EPOCHS, alpha=1e-2)

model1.compile(
    optimizer=keras.optimizers.Adam(learning_rate=lr),
    loss=keras.losses.CategoricalCrossentropy(),
    metrics=[
        keras.metrics.CategoricalAccuracy(name="accuracy"),
        keras.metrics.TopKCategoricalAccuracy(k=5, name="top5_acc"),
    ],
)

cb = [
    keras.callbacks.ModelCheckpoint("/content/task1_best.keras", save_best_only=True, monitor="val_accuracy", mode="max", verbose=1),
    keras.callbacks.EarlyStopping(monitor="val_accuracy", patience=15, restore_best_weights=True),
]

history = model1.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=cb, verbose=1)

print("Eval:", model1.evaluate(val_ds, verbose=1))

final_path = "/content/task1_custom_final.keras"
model1.save(final_path)

from google.colab import files
files.download("/content/task1_best.keras")
files.download(final_path)

     
Model: "task1_scratch"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer_25      │ (None, 160, 160,  │          0 │ -                 │
│ (InputLayer)        │ 3)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ aug (Sequential)    │ (None, 160, 160,  │          0 │ input_layer_25[0… │
│                     │ 3)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ rescaling_7         │ (None, 160, 160,  │          0 │ aug[0][0]         │
│ (Rescaling)         │ 3)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_3 (Conv2D)   │ (None, 80, 80,    │        864 │ rescaling_7[0][0] │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ stem_ln             │ (None, 80, 80,    │         64 │ conv2d_3[0][0]    │
│ (LayerNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ stem_relu (ReLU)    │ (None, 80, 80,    │          0 │ stem_ln[0][0]     │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b1_dw               │ (None, 80, 80,    │        288 │ stem_relu[0][0]   │
│ (DepthwiseConv2D)   │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b1_a_ln             │ (None, 80, 80,    │         64 │ b1_dw[0][0]       │
│ (LayerNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b1_a_relu (ReLU)    │ (None, 80, 80,    │          0 │ b1_a_ln[0][0]     │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b1_pw (Conv2D)      │ (None, 80, 80,    │      2,048 │ b1_a_relu[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b1_b_ln             │ (None, 80, 80,    │        128 │ b1_pw[0][0]       │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b1_b_relu (ReLU)    │ (None, 80, 80,    │          0 │ b1_b_ln[0][0]     │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b2_dw               │ (None, 40, 40,    │        576 │ b1_b_relu[0][0]   │
│ (DepthwiseConv2D)   │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b2_a_ln             │ (None, 40, 40,    │        128 │ b2_dw[0][0]       │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b2_a_relu (ReLU)    │ (None, 40, 40,    │          0 │ b2_a_ln[0][0]     │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b2_pw (Conv2D)      │ (None, 40, 40,    │      8,192 │ b2_a_relu[0][0]   │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b2_b_ln             │ (None, 40, 40,    │        256 │ b2_pw[0][0]       │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b2_b_relu (ReLU)    │ (None, 40, 40,    │          0 │ b2_b_ln[0][0]     │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b3_dw               │ (None, 40, 40,    │      1,152 │ b2_b_relu[0][0]   │
│ (DepthwiseConv2D)   │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b3_a_ln             │ (None, 40, 40,    │        256 │ b3_dw[0][0]       │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b3_a_relu (ReLU)    │ (None, 40, 40,    │          0 │ b3_a_ln[0][0]     │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b3_pw (Conv2D)      │ (None, 40, 40,    │     16,384 │ b3_a_relu[0][0]   │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b3_b_ln             │ (None, 40, 40,    │        256 │ b3_pw[0][0]       │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b3_b_relu (ReLU)    │ (None, 40, 40,    │          0 │ b3_b_ln[0][0]     │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b3_add (Add)        │ (None, 40, 40,    │          0 │ b3_b_relu[0][0],  │
│                     │ 128)              │            │ b2_b_relu[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b4_dw               │ (None, 20, 20,    │      1,152 │ b3_add[0][0]      │
│ (DepthwiseConv2D)   │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b4_a_ln             │ (None, 20, 20,    │        256 │ b4_dw[0][0]       │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b4_a_relu (ReLU)    │ (None, 20, 20,    │          0 │ b4_a_ln[0][0]     │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b4_pw (Conv2D)      │ (None, 20, 20,    │     32,768 │ b4_a_relu[0][0]   │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b4_b_ln             │ (None, 20, 20,    │        512 │ b4_pw[0][0]       │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b4_b_relu (ReLU)    │ (None, 20, 20,    │          0 │ b4_b_ln[0][0]     │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b5_dw               │ (None, 20, 20,    │      2,304 │ b4_b_relu[0][0]   │
│ (DepthwiseConv2D)   │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b5_a_ln             │ (None, 20, 20,    │        512 │ b5_dw[0][0]       │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b5_a_relu (ReLU)    │ (None, 20, 20,    │          0 │ b5_a_ln[0][0]     │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b5_pw (Conv2D)      │ (None, 20, 20,    │     65,536 │ b5_a_relu[0][0]   │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b5_b_ln             │ (None, 20, 20,    │        512 │ b5_pw[0][0]       │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b5_b_relu (ReLU)    │ (None, 20, 20,    │          0 │ b5_b_ln[0][0]     │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b5_add (Add)        │ (None, 20, 20,    │          0 │ b5_b_relu[0][0],  │
│                     │ 256)              │            │ b4_b_relu[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b6_dw               │ (None, 20, 20,    │      2,304 │ b5_add[0][0]      │
│ (DepthwiseConv2D)   │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b6_a_ln             │ (None, 20, 20,    │        512 │ b6_dw[0][0]       │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b6_a_relu (ReLU)    │ (None, 20, 20,    │          0 │ b6_a_ln[0][0]     │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b6_pw (Conv2D)      │ (None, 20, 20,    │     65,536 │ b6_a_relu[0][0]   │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b6_b_ln             │ (None, 20, 20,    │        512 │ b6_pw[0][0]       │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b6_b_relu (ReLU)    │ (None, 20, 20,    │          0 │ b6_b_ln[0][0]     │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ b6_add (Add)        │ (None, 20, 20,    │          0 │ b6_b_relu[0][0],  │
│                     │ 256)              │            │ b5_add[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_average_poo… │ (None, 256)       │          0 │ b6_add[0][0]      │
│ (GlobalAveragePool… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_11          │ (None, 256)       │          0 │ global_average_p… │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_25 (Dense)    │ (None, 10)        │      2,570 │ dropout_11[0][0]  │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 205,642 (803.29 KB)
 Trainable params: 205,642 (803.29 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/80
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.1037 - loss: 3.1559 - top5_acc: 0.5436
Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to /content/task1_best.keras
13/13 ━━━━━━━━━━━━━━━━━━━━ 10s 209ms/step - accuracy: 0.1049 - loss: 3.1491 - top5_acc: 0.5444 - val_accuracy: 0.1000 - val_loss: 2.5532 - val_top5_acc: 0.5000
Epoch 2/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.0710 - loss: 2.7977 - top5_acc: 0.4458
Epoch 2: val_accuracy did not improve from 0.10000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 69ms/step - accuracy: 0.0687 - loss: 2.7984 - top5_acc: 0.4407 - val_accuracy: 0.1000 - val_loss: 2.4218 - val_top5_acc: 0.5200
Epoch 3/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.0543 - loss: 2.7466 - top5_acc: 0.4413
Epoch 3: val_accuracy did not improve from 0.10000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 64ms/step - accuracy: 0.0586 - loss: 2.7358 - top5_acc: 0.4419 - val_accuracy: 0.1000 - val_loss: 2.3231 - val_top5_acc: 0.4800
Epoch 4/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.0811 - loss: 2.5735 - top5_acc: 0.4030
Epoch 4: val_accuracy did not improve from 0.10000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.0845 - loss: 2.5640 - top5_acc: 0.4161 - val_accuracy: 0.1000 - val_loss: 2.3259 - val_top5_acc: 0.5000
Epoch 5/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.0881 - loss: 2.5465 - top5_acc: 0.3952
Epoch 5: val_accuracy did not improve from 0.10000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.0891 - loss: 2.5451 - top5_acc: 0.3994 - val_accuracy: 0.1000 - val_loss: 2.3317 - val_top5_acc: 0.5000
Epoch 6/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1110 - loss: 2.5196 - top5_acc: 0.4223
Epoch 6: val_accuracy improved from 0.10000 to 0.16000, saving model to /content/task1_best.keras
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 79ms/step - accuracy: 0.1087 - loss: 2.5144 - top5_acc: 0.4284 - val_accuracy: 0.1600 - val_loss: 2.2663 - val_top5_acc: 0.6000
Epoch 7/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1111 - loss: 2.4580 - top5_acc: 0.4819
Epoch 7: val_accuracy did not improve from 0.16000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.1152 - loss: 2.4523 - top5_acc: 0.4874 - val_accuracy: 0.1200 - val_loss: 2.2493 - val_top5_acc: 0.6200
Epoch 8/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1270 - loss: 2.3397 - top5_acc: 0.6334
Epoch 8: val_accuracy improved from 0.16000 to 0.22000, saving model to /content/task1_best.keras
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 80ms/step - accuracy: 0.1253 - loss: 2.3472 - top5_acc: 0.6236 - val_accuracy: 0.2200 - val_loss: 2.1554 - val_top5_acc: 0.7000
Epoch 9/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1156 - loss: 2.3333 - top5_acc: 0.5679
Epoch 9: val_accuracy did not improve from 0.22000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 64ms/step - accuracy: 0.1226 - loss: 2.3294 - top5_acc: 0.5710 - val_accuracy: 0.2200 - val_loss: 2.1708 - val_top5_acc: 0.7000
Epoch 10/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.0918 - loss: 2.3460 - top5_acc: 0.5666
Epoch 10: val_accuracy improved from 0.22000 to 0.24000, saving model to /content/task1_best.keras
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 80ms/step - accuracy: 0.0923 - loss: 2.3404 - top5_acc: 0.5735 - val_accuracy: 0.2400 - val_loss: 2.0768 - val_top5_acc: 0.7000
Epoch 11/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2720 - loss: 2.1742 - top5_acc: 0.6843
Epoch 11: val_accuracy did not improve from 0.24000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.2660 - loss: 2.1718 - top5_acc: 0.6865 - val_accuracy: 0.2400 - val_loss: 2.0758 - val_top5_acc: 0.7200
Epoch 12/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.1844 - loss: 2.2456 - top5_acc: 0.6651
Epoch 12: val_accuracy improved from 0.24000 to 0.30000, saving model to /content/task1_best.keras
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 79ms/step - accuracy: 0.1788 - loss: 2.2461 - top5_acc: 0.6637 - val_accuracy: 0.3000 - val_loss: 2.0483 - val_top5_acc: 0.7400
Epoch 13/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.1912 - loss: 2.1275 - top5_acc: 0.7454
Epoch 13: val_accuracy improved from 0.30000 to 0.34000, saving model to /content/task1_best.keras
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 94ms/step - accuracy: 0.1874 - loss: 2.1337 - top5_acc: 0.7432 - val_accuracy: 0.3400 - val_loss: 2.0023 - val_top5_acc: 0.7200
Epoch 14/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1631 - loss: 2.0898 - top5_acc: 0.7208
Epoch 14: val_accuracy improved from 0.34000 to 0.42000, saving model to /content/task1_best.keras
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 96ms/step - accuracy: 0.1691 - loss: 2.0935 - top5_acc: 0.7228 - val_accuracy: 0.4200 - val_loss: 2.0825 - val_top5_acc: 0.7600
Epoch 15/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2273 - loss: 2.0406 - top5_acc: 0.7808
Epoch 15: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 73ms/step - accuracy: 0.2312 - loss: 2.0349 - top5_acc: 0.7835 - val_accuracy: 0.3400 - val_loss: 2.0329 - val_top5_acc: 0.8200
Epoch 16/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2220 - loss: 2.1036 - top5_acc: 0.7403
Epoch 16: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 67ms/step - accuracy: 0.2253 - loss: 2.1003 - top5_acc: 0.7431 - val_accuracy: 0.2000 - val_loss: 2.0452 - val_top5_acc: 0.7800
Epoch 17/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2824 - loss: 1.9113 - top5_acc: 0.8060
Epoch 17: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.2799 - loss: 1.9145 - top5_acc: 0.8065 - val_accuracy: 0.3400 - val_loss: 2.1271 - val_top5_acc: 0.8200
Epoch 18/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2334 - loss: 1.9847 - top5_acc: 0.7467
Epoch 18: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.2358 - loss: 1.9866 - top5_acc: 0.7472 - val_accuracy: 0.3200 - val_loss: 1.9548 - val_top5_acc: 0.8000
Epoch 19/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2816 - loss: 1.9828 - top5_acc: 0.8066
Epoch 19: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.2828 - loss: 1.9771 - top5_acc: 0.8057 - val_accuracy: 0.3400 - val_loss: 2.0313 - val_top5_acc: 0.8600
Epoch 20/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2395 - loss: 1.8818 - top5_acc: 0.8571
Epoch 20: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 66ms/step - accuracy: 0.2431 - loss: 1.8773 - top5_acc: 0.8582 - val_accuracy: 0.3400 - val_loss: 1.9218 - val_top5_acc: 0.8800
Epoch 21/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3035 - loss: 1.8186 - top5_acc: 0.8196
Epoch 21: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 66ms/step - accuracy: 0.3052 - loss: 1.8127 - top5_acc: 0.8233 - val_accuracy: 0.2800 - val_loss: 2.0423 - val_top5_acc: 0.8400
Epoch 22/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3109 - loss: 1.7343 - top5_acc: 0.8862
Epoch 22: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.3094 - loss: 1.7427 - top5_acc: 0.8832 - val_accuracy: 0.3400 - val_loss: 1.9193 - val_top5_acc: 0.8800
Epoch 23/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2750 - loss: 1.8412 - top5_acc: 0.8614
Epoch 23: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 66ms/step - accuracy: 0.2815 - loss: 1.8327 - top5_acc: 0.8634 - val_accuracy: 0.3400 - val_loss: 1.9202 - val_top5_acc: 0.8400
Epoch 24/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3158 - loss: 1.7288 - top5_acc: 0.8953
Epoch 24: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.3207 - loss: 1.7162 - top5_acc: 0.8967 - val_accuracy: 0.4000 - val_loss: 1.8502 - val_top5_acc: 0.8400
Epoch 25/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3539 - loss: 1.6612 - top5_acc: 0.8972
Epoch 25: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.3640 - loss: 1.6498 - top5_acc: 0.8984 - val_accuracy: 0.4200 - val_loss: 1.8276 - val_top5_acc: 0.8600
Epoch 26/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3986 - loss: 1.6343 - top5_acc: 0.9077
Epoch 26: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.4016 - loss: 1.6287 - top5_acc: 0.9074 - val_accuracy: 0.4000 - val_loss: 1.9316 - val_top5_acc: 0.8600
Epoch 27/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.4175 - loss: 1.5216 - top5_acc: 0.9331
Epoch 27: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.4257 - loss: 1.5121 - top5_acc: 0.9355 - val_accuracy: 0.4200 - val_loss: 1.8136 - val_top5_acc: 0.8600
Epoch 28/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.4067 - loss: 1.4273 - top5_acc: 0.9250
Epoch 28: val_accuracy did not improve from 0.42000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 76ms/step - accuracy: 0.4100 - loss: 1.4258 - top5_acc: 0.9257 - val_accuracy: 0.4200 - val_loss: 1.8095 - val_top5_acc: 0.8400
Epoch 29/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.4405 - loss: 1.4480 - top5_acc: 0.9421
Epoch 29: val_accuracy improved from 0.42000 to 0.46000, saving model to /content/task1_best.keras
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 91ms/step - accuracy: 0.4483 - loss: 1.4399 - top5_acc: 0.9425 - val_accuracy: 0.4600 - val_loss: 1.7968 - val_top5_acc: 0.9000
Epoch 30/80
13/13 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.4374 - loss: 1.3894 - top5_acc: 0.9319
Epoch 30: val_accuracy did not improve from 0.46000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 72ms/step - accuracy: 0.4398 - loss: 1.3863 - top5_acc: 0.9325 - val_accuracy: 0.4600 - val_loss: 1.8134 - val_top5_acc: 0.8800
Epoch 31/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5730 - loss: 1.2851 - top5_acc: 0.9681
Epoch 31: val_accuracy improved from 0.46000 to 0.50000, saving model to /content/task1_best.keras
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 79ms/step - accuracy: 0.5682 - loss: 1.2857 - top5_acc: 0.9691 - val_accuracy: 0.5000 - val_loss: 1.7994 - val_top5_acc: 0.8800
Epoch 32/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.5485 - loss: 1.2609 - top5_acc: 0.9542
Epoch 32: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 66ms/step - accuracy: 0.5458 - loss: 1.2616 - top5_acc: 0.9551 - val_accuracy: 0.4600 - val_loss: 1.8591 - val_top5_acc: 0.8600
Epoch 33/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5006 - loss: 1.3747 - top5_acc: 0.9521
Epoch 33: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 64ms/step - accuracy: 0.4991 - loss: 1.3743 - top5_acc: 0.9525 - val_accuracy: 0.4600 - val_loss: 1.8773 - val_top5_acc: 0.9000
Epoch 34/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.4680 - loss: 1.2801 - top5_acc: 0.9597
Epoch 34: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 66ms/step - accuracy: 0.4747 - loss: 1.2734 - top5_acc: 0.9576 - val_accuracy: 0.4600 - val_loss: 1.8143 - val_top5_acc: 0.9200
Epoch 35/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.5006 - loss: 1.2728 - top5_acc: 0.9526
Epoch 35: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.5062 - loss: 1.2719 - top5_acc: 0.9515 - val_accuracy: 0.4400 - val_loss: 1.9738 - val_top5_acc: 0.8600
Epoch 36/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.4699 - loss: 1.2449 - top5_acc: 0.9732
Epoch 36: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.4778 - loss: 1.2422 - top5_acc: 0.9706 - val_accuracy: 0.3600 - val_loss: 2.1648 - val_top5_acc: 0.9000
Epoch 37/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5320 - loss: 1.2093 - top5_acc: 0.9697
Epoch 37: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.5318 - loss: 1.2128 - top5_acc: 0.9683 - val_accuracy: 0.4400 - val_loss: 1.8801 - val_top5_acc: 0.9200
Epoch 38/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.5709 - loss: 1.2711 - top5_acc: 0.9320
Epoch 38: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.5665 - loss: 1.2696 - top5_acc: 0.9331 - val_accuracy: 0.4200 - val_loss: 1.9415 - val_top5_acc: 0.8600
Epoch 39/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.6434 - loss: 1.1299 - top5_acc: 0.9904
Epoch 39: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 66ms/step - accuracy: 0.6351 - loss: 1.1360 - top5_acc: 0.9889 - val_accuracy: 0.4200 - val_loss: 1.7641 - val_top5_acc: 0.8800
Epoch 40/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6130 - loss: 1.0973 - top5_acc: 0.9850
Epoch 40: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 66ms/step - accuracy: 0.6111 - loss: 1.1014 - top5_acc: 0.9836 - val_accuracy: 0.4800 - val_loss: 1.9638 - val_top5_acc: 0.8800
Epoch 41/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.5853 - loss: 1.0634 - top5_acc: 0.9778
Epoch 41: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 65ms/step - accuracy: 0.5888 - loss: 1.0664 - top5_acc: 0.9774 - val_accuracy: 0.4400 - val_loss: 1.8941 - val_top5_acc: 0.9200
Epoch 42/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6167 - loss: 1.0465 - top5_acc: 0.9597
Epoch 42: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 71ms/step - accuracy: 0.6179 - loss: 1.0462 - top5_acc: 0.9619 - val_accuracy: 0.3600 - val_loss: 1.9085 - val_top5_acc: 0.8800
Epoch 43/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6229 - loss: 0.9734 - top5_acc: 0.9881
Epoch 43: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 77ms/step - accuracy: 0.6268 - loss: 0.9746 - top5_acc: 0.9883 - val_accuracy: 0.4000 - val_loss: 1.8847 - val_top5_acc: 0.8800
Epoch 44/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.6409 - loss: 0.9592 - top5_acc: 0.9894
Epoch 44: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 78ms/step - accuracy: 0.6458 - loss: 0.9555 - top5_acc: 0.9880 - val_accuracy: 0.4800 - val_loss: 1.7209 - val_top5_acc: 0.8800
Epoch 45/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6320 - loss: 0.9197 - top5_acc: 0.9870
Epoch 45: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 68ms/step - accuracy: 0.6360 - loss: 0.9219 - top5_acc: 0.9853 - val_accuracy: 0.5000 - val_loss: 1.8345 - val_top5_acc: 0.9000
Epoch 46/80
12/13 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.7482 - loss: 0.8156 - top5_acc: 0.9803
Epoch 46: val_accuracy did not improve from 0.50000
13/13 ━━━━━━━━━━━━━━━━━━━━ 1s 66ms/step - accuracy: 0.7470 - loss: 0.8193 - top5_acc: 0.9809 - val_accuracy: 0.4800 - val_loss: 1.7707 - val_top5_acc: 0.8800
4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - accuracy: 0.4500 - loss: 1.9112 - top5_acc: 0.8957
Eval: [1.7994211912155151, 0.5, 0.8799999952316284]
